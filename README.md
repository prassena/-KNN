# KNN

K-Nearest Neighbors (KNN) is one of the simplest algorithms used in Machine Learning for regression and classification problem. KNN algorithms use data and classify new data points based on similarity measures (e.g. distance function). Classification is done by a majority vote to its neighbors. The data is assigned to the class which has the nearest neighbors. As you increase the number of nearest neighbors, the value of k, accuracy might increase.

The ipynb shows the implimentation of KNN on DonorsChoose Dataset and how to tune Hyper paramater (K value) in K-nearest Neighbors in order to get good model.

The data has been prerocessed like removel of duplicate ,stop words, special character and hyper txt links etc 

The processed Data have been analysed - univarient analysis to know more about the data .

Metric used tofind best model was AUC (Area under ROC).

# Facing error while loading IPYNB "Sorry, something went wrong. Reload?"

Go to this url https://nbviewer.jupyter.org/ and copy paste the following link " https://github.com/prassena/-KNN/blob/master/KNN.ipynb " in the text box seen
